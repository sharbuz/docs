## Container Resource Requirements

The table below specifies resource requirements for AI/Run CodeMie components sized for **high-scale production deployments** supporting 500+ concurrent users.

| Component           | Pods                     | RAM   | vCPU | Storage            |
| ------------------- | ------------------------ | ----- | ---- | ------------------ |
| CodeMie API         | 2                        | 8Gi   | 4.0  | –                  |
| CodeMie UI          | 1                        | 128Mi | 0.1  | –                  |
| Elasticsearch       | 2                        | 16Gi  | 4.0  | 100-200 GB per pod |
| Kibana              | 1                        | 1Gi   | 1.0  | –                  |
| Mermaid-server      | 1                        | 512Mi | 1.0  | –                  |
| PostgreSQL          | Managed service in cloud | –     | –    | 30-50 GB           |
| Keycloak + DB       | 1 + 1                    | 4Gi   | 2.0  | 1 GB               |
| Oauth2-proxy        | 1                        | 128Mi | 0.1  | –                  |
| NATS + Auth Callout | 1 + 1                    | 512Mi | 1.0  | –                  |
| MCP Connect         | 1                        | 1Gi   | 0.5  | –                  |
| Fluent Bit          | DaemonSet                | 128Mi | 0.1  | –                  |
| LLM Proxy           | 1                        | 1Gi   | 1.0  | –                  |

:::info Scaling Considerations

The listed requirements are designed for high-scale production deployments (500+ users). For smaller teams and lower concurrency, some resources can be scaled down:

- **User Concurrency**: Scale API replicas based on actual concurrent user counts
- **Data Volume**: Elasticsearch storage grows with datasources amount and size and log retention policies
- **Query Load**: PostgreSQL managed service tier depends on transaction volume and query complexity
- **LLM Proxy**: Resource requirements depend on the exact LLM proxy type being used

:::
